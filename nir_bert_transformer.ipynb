{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250b39b9-4a3b-4576-a0bf-bebc86873448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import (AutoTokenizer, AutoModelForTokenClassification,\n",
    "    pipeline, TrainingArguments, Trainer, DataCollatorForTokenClassification)\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c48c0c1-ea8f-41b0-9ad9-02e97170e449",
   "metadata": {},
   "source": [
    "Загружаем датасет и преобразуем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8555e332-18e2-4bc6-ac16-5e89c8eb1c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ner.csv\")\n",
    "data.dropna(inplace=True)\n",
    "del data['POS']\n",
    "del data['Sentence #']\n",
    "data = data.rename(columns={'Sentence': 'tokens','Tag': 'ner_tags'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e9259e-8f93-47e1-be2a-22bfd0ba8bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "import ast\n",
    "\n",
    "for i in range(len(data)):\n",
    "    tags = ast.literal_eval(data['ner_tags'][i])\n",
    "    data['ner_tags'][i] = [str(word.upper()) for word in tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b734770-56b0-4b1f-88c1-12f399d587db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>[O, O, O, O, O, O, B-GEO, O, O, O, O, O, B-GEO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Families of soldiers killed in the conflict jo...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They marched from the Houses of Parliament to ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-GEO, I-GEO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Police put the number of marchers at 10,000 wh...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The protest comes on the eve of the annual con...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-GEO, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47954</th>\n",
       "      <td>Indian border security forces are accusing the...</td>\n",
       "      <td>[B-GPE, O, O, O, O, O, O, B-GPE, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47955</th>\n",
       "      <td>Indian officials said no one was injured in Sa...</td>\n",
       "      <td>[B-GPE, O, O, O, O, O, O, O, B-TIM, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47956</th>\n",
       "      <td>Two more landed in fields belonging to a nearb...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47957</th>\n",
       "      <td>They say not all of the rockets exploded upon ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47958</th>\n",
       "      <td>Indian forces said they responded to the attack</td>\n",
       "      <td>[B-GPE, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47959 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      Thousands of demonstrators have marched throug...   \n",
       "1      Families of soldiers killed in the conflict jo...   \n",
       "2      They marched from the Houses of Parliament to ...   \n",
       "3      Police put the number of marchers at 10,000 wh...   \n",
       "4      The protest comes on the eve of the annual con...   \n",
       "...                                                  ...   \n",
       "47954  Indian border security forces are accusing the...   \n",
       "47955  Indian officials said no one was injured in Sa...   \n",
       "47956  Two more landed in fields belonging to a nearb...   \n",
       "47957  They say not all of the rockets exploded upon ...   \n",
       "47958    Indian forces said they responded to the attack   \n",
       "\n",
       "                                                ner_tags  \n",
       "0      [O, O, O, O, O, O, B-GEO, O, O, O, O, O, B-GEO...  \n",
       "1      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2      [O, O, O, O, O, O, O, O, O, O, O, B-GEO, I-GEO...  \n",
       "3          [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "4      [O, O, O, O, O, O, O, O, O, O, O, B-GEO, O, O,...  \n",
       "...                                                  ...  \n",
       "47954  [B-GPE, O, O, O, O, O, O, B-GPE, O, O, O, O, O...  \n",
       "47955  [B-GPE, O, O, O, O, O, O, O, B-TIM, O, O, O, O...  \n",
       "47956                  [O, O, O, O, O, O, O, O, O, O, O]  \n",
       "47957                  [O, O, O, O, O, O, O, O, O, O, O]  \n",
       "47958                       [B-GPE, O, O, O, O, O, O, O]  \n",
       "\n",
       "[47959 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f82da4f-164a-4489-aaf6-293ad64ab601",
   "metadata": {},
   "source": [
    "Находим уникальные метки слов в датасете для задачи NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fc9afaa-9230-40ff-b464-204577538edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-ART',\n",
       " 'B-EVE',\n",
       " 'B-GEO',\n",
       " 'B-GPE',\n",
       " 'B-NAT',\n",
       " 'B-ORG',\n",
       " 'B-PER',\n",
       " 'B-TIM',\n",
       " 'I-ART',\n",
       " 'I-EVE',\n",
       " 'I-GEO',\n",
       " 'I-GPE',\n",
       " 'I-NAT',\n",
       " 'I-ORG',\n",
       " 'I-PER',\n",
       " 'I-TIM',\n",
       " 'O'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_codes = set([val for sublist in data['ner_tags'].values for val in sublist])\n",
    "entity_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2929b5-6356-4807-9f04-3c82f350746f",
   "metadata": {},
   "source": [
    "## Метки\n",
    "\n",
    "\n",
    "\n",
    "| Код в датасете | Описание | Код в предобученной модели |\n",
    "|------|------|------|\n",
    "| ORG | Organization | ORG |\n",
    "| PER | Person| PER |\n",
    "| GEO | Geographical Entity| LOC |\n",
    "| GPE | Geopolitical Entity| MISC - Miscellaneous entity |\n",
    "| ART | Artifact| O |\n",
    "| EVE | Event| O |\n",
    "| NAT | Natural Phenomenon| O |\n",
    "| TIM | Time indicator| O |\n",
    "| O | Outside of a named entity| O |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a320b4e-2043-46ae-8d7b-08c146fe7ce1",
   "metadata": {},
   "source": [
    "Проверка предобученной модели трансформера для задачи NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13d42e00-fdd8-4a4e-8a1f-7b833fc02cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "pipe = pipeline(\"ner\", model=\"dslim/bert-base-NER\", tokenizer=tokenizer,device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bc8686a-4cfd-4a9b-b68a-ae1552b2e740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 47959/47959 [13:26<00:00, 59.45it/s]\n"
     ]
    }
   ],
   "source": [
    "%%capture cap --no-stderr\n",
    "from tqdm import tqdm\n",
    "preds = []\n",
    "for i in tqdm(data.values):\n",
    "  pred = pipe(i[0])\n",
    "  preds.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd7aaff-5bb9-49fc-97e3-1fe3279419c8",
   "metadata": {},
   "source": [
    "Процент предсказаний, где верно предсказано количество именованных сущностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "195bc2ce-eb22-4b47-ab25-fb487aab545c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'36.07%'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=0\n",
    "for v1,v2 in zip(data.values, preds):\n",
    "    true = list(filter(lambda x: x != 'O', v1[1]))\n",
    "    if len(true)==len(v2):\n",
    "        k+=1\n",
    "\"{:.2%}\".format(k/len(data.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be67e9-afa3-4133-9045-6dccb60d8d32",
   "metadata": {},
   "source": [
    "Проведем дообучение модели трансформера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42853b53-2ace-4083-b731-7cc2b0f7214f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-NAT': 0, 'B-TIM': 1, 'B-ART': 2, 'I-EVE': 3, 'B-GEO': 4, 'I-PER': 5, 'B-EVE': 6, 'B-ORG': 7, 'I-GEO': 8, 'B-NAT': 9, 'I-TIM': 10, 'I-GPE': 11, 'B-GPE': 12, 'I-ART': 13, 'I-ORG': 14, 'B-PER': 15, 'O': 16} \n",
      " {0: 'I-NAT', 1: 'B-TIM', 2: 'B-ART', 3: 'I-EVE', 4: 'B-GEO', 5: 'I-PER', 6: 'B-EVE', 7: 'B-ORG', 8: 'I-GEO', 9: 'B-NAT', 10: 'I-TIM', 11: 'I-GPE', 12: 'B-GPE', 13: 'I-ART', 14: 'I-ORG', 15: 'B-PER', 16: 'O'}\n"
     ]
    }
   ],
   "source": [
    "label2id = {}\n",
    "dict([ (elem, 0) for elem in entity_codes ])\n",
    "k=0\n",
    "for i in entity_codes:\n",
    "    label2id[i]=k\n",
    "    k+=1\n",
    "id2label = {y: x for x, y in label2id.items()}\n",
    "print(label2id,\"\\n\",id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "309cb5a9-9cfd-4ac7-8425-1261027ad52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "k=0\n",
    "data['labels'] = data['ner_tags']\n",
    "for i in range(len(data)):\n",
    "    data['tokens'][i] = data['tokens'][i].split()\n",
    "    data['labels'][i] = [label2id[x] for x in data['labels'][i]]\n",
    "    if len(data['ner_tags'][i]) != len(data['tokens'][i]):\n",
    "        data.drop([i],inplace=True)\n",
    "        k+=1\n",
    "data['labels'] = data['labels'].apply(lambda x: [int(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08270358-9de4-4255-9107-296d771afcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-GEO, O, O, O, O, O, B-GEO...</td>\n",
       "      <td>[16, 16, 16, 16, 16, 16, 4, 16, 16, 16, 16, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Families, of, soldiers, killed, in, the, conf...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[They, marched, from, the, Houses, of, Parliam...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-GEO, I-GEO...</td>\n",
       "      <td>[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Police, put, the, number, of, marchers, at, 1...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The, protest, comes, on, the, eve, of, the, a...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-GEO, O, O,...</td>\n",
       "      <td>[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47954</th>\n",
       "      <td>[Indian, border, security, forces, are, accusi...</td>\n",
       "      <td>[B-GPE, O, O, O, O, O, O, B-GPE, O, O, O, O, O...</td>\n",
       "      <td>[12, 16, 16, 16, 16, 16, 16, 12, 16, 16, 16, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47955</th>\n",
       "      <td>[Indian, officials, said, no, one, was, injure...</td>\n",
       "      <td>[B-GPE, O, O, O, O, O, O, O, B-TIM, O, O, O, O...</td>\n",
       "      <td>[12, 16, 16, 16, 16, 16, 16, 16, 1, 16, 16, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47956</th>\n",
       "      <td>[Two, more, landed, in, fields, belonging, to,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47957</th>\n",
       "      <td>[They, say, not, all, of, the, rockets, explod...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47958</th>\n",
       "      <td>[Indian, forces, said, they, responded, to, th...</td>\n",
       "      <td>[B-GPE, O, O, O, O, O, O, O]</td>\n",
       "      <td>[12, 16, 16, 16, 16, 16, 16, 16]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47955 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [Thousands, of, demonstrators, have, marched, ...   \n",
       "1      [Families, of, soldiers, killed, in, the, conf...   \n",
       "2      [They, marched, from, the, Houses, of, Parliam...   \n",
       "3      [Police, put, the, number, of, marchers, at, 1...   \n",
       "4      [The, protest, comes, on, the, eve, of, the, a...   \n",
       "...                                                  ...   \n",
       "47954  [Indian, border, security, forces, are, accusi...   \n",
       "47955  [Indian, officials, said, no, one, was, injure...   \n",
       "47956  [Two, more, landed, in, fields, belonging, to,...   \n",
       "47957  [They, say, not, all, of, the, rockets, explod...   \n",
       "47958  [Indian, forces, said, they, responded, to, th...   \n",
       "\n",
       "                                                ner_tags  \\\n",
       "0      [O, O, O, O, O, O, B-GEO, O, O, O, O, O, B-GEO...   \n",
       "1      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2      [O, O, O, O, O, O, O, O, O, O, O, B-GEO, I-GEO...   \n",
       "3          [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4      [O, O, O, O, O, O, O, O, O, O, O, B-GEO, O, O,...   \n",
       "...                                                  ...   \n",
       "47954  [B-GPE, O, O, O, O, O, O, B-GPE, O, O, O, O, O...   \n",
       "47955  [B-GPE, O, O, O, O, O, O, O, B-TIM, O, O, O, O...   \n",
       "47956                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "47957                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "47958                       [B-GPE, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                  labels  \n",
       "0      [16, 16, 16, 16, 16, 16, 4, 16, 16, 16, 16, 16...  \n",
       "1      [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 1...  \n",
       "2      [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 4...  \n",
       "3      [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 1...  \n",
       "4      [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 4...  \n",
       "...                                                  ...  \n",
       "47954  [12, 16, 16, 16, 16, 16, 16, 12, 16, 16, 16, 1...  \n",
       "47955  [12, 16, 16, 16, 16, 16, 16, 16, 1, 16, 16, 16...  \n",
       "47956       [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]  \n",
       "47957       [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]  \n",
       "47958                   [12, 16, 16, 16, 16, 16, 16, 16]  \n",
       "\n",
       "[47955 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e226b1e5-9d5f-47d4-ace7-36c1be40d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество некорректных значений:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество некорректных значений: \",k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e6257-b2c6-42a1-8b6a-5c4fedb5ca75",
   "metadata": {},
   "source": [
    "Делим данные для проверки и обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2673180a-8769-435e-a76e-42480bb37a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test = train_test_split(data, test_size=0.3)\n",
    "data_val, data_test = train_test_split(data_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05fba989-54f3-4fb8-9389-59dc15b3066c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'labels'],\n",
       "        num_rows: 33568\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'labels'],\n",
       "        num_rows: 7193\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "ds = DatasetDict()\n",
    "ds['train'] = Dataset.from_pandas(data_train).remove_columns([\"__index_level_0__\"])\n",
    "ds['validation'] = Dataset.from_pandas(data_val).remove_columns([\"__index_level_0__\"])\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ae32ab2-f417-4b05-ba9f-f3fbb7228d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'ner_tags': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6826e745-b4f8-4132-9a8a-fb4667314d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de43bf079324fbfb0f8bd6402a0aa42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33568 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e97f5a9e034649ba8c7925f16bde6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7193 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 33568\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 7193\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"labels\"]):\n",
    "        labels.append(label)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "tokenized_ds = ds.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e87f40d9-b6dd-454f-afbe-e43dd4a11cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'ner_tags': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9a68ab2-d8cb-4817-86d4-e104ec542a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dslim/bert-base-NER and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([17]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([17, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"dslim/bert-base-NER\", num_labels=17, id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc5d5f-e626-4d4c-aecb-cafcee870446",
   "metadata": {},
   "source": [
    "Дообучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b1969f3-2348-44d4-9f85-321e5049af8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6294' max='6294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6294/6294 53:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.189800</td>\n",
       "      <td>0.150947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>0.102621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.081900</td>\n",
       "      <td>0.073359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6294, training_loss=0.1598629974205228, metrics={'train_runtime': 3215.9139, 'train_samples_per_second': 31.314, 'train_steps_per_second': 1.957, 'total_flos': 2350625902925664.0, 'train_loss': 0.1598629974205228, 'epoch': 3.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"model\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"].remove_columns([\"ner_tags\",'tokens']),\n",
    "    eval_dataset=tokenized_ds[\"validation\"].remove_columns([\"ner_tags\",'tokens']),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34844dd3-dc30-440f-8952-93fc509fd38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"model/checkpoint-6294\"\n",
    "pipe = pipeline(\"ner\", model=model_name_or_path,tokenizer=tokenizer,device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59bfd41f-fabe-44b1-b1a1-62191ab0f68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7194/7194 [05:30<00:00, 21.79it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for i in tqdm(data_test.values):\n",
    "  pred = pipe(' '.join(i[0]))\n",
    "  preds.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48289d20-37c3-4843-aefd-777cc0699e6f",
   "metadata": {},
   "source": [
    "Процент верных ответов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a075990a-001b-4eb8-932a-0c43e91754d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.17%'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=0\n",
    "for v1,v2 in zip(data_test.values, preds):\n",
    "    true = list(filter(lambda x: x != 'O', v1[1]))\n",
    "    if true==[x.get(\"entity\") for x in v2]:\n",
    "        k+=1\n",
    "\"{:.2%}\".format(k/len(data.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91705d1-0ba0-4905-8b55-1e38691d69b4",
   "metadata": {},
   "source": [
    "Обучим модель трансформер distilbert/distilbert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48b2ce26-8f23-4a2f-918b-2ddd367ab6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "new_tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "new_data_collator = DataCollatorForTokenClassification(tokenizer=new_tokenizer)\n",
    "new_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=17, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0ed624b-43ee-4d16-b36e-b7e715439f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fd15b3d67f4f1fb3b7b5786f9a38dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33568 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0dbba3809042338f0816f81f89b58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7193 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 33568\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 7193\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = new_tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"labels\"]):\n",
    "        labels.append(label)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "new_tokenized_ds = ds.map(tokenize_and_align_labels, batched=True)\n",
    "new_tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "230b4aac-617d-43d7-9398-fa6be1a10a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6294' max='6294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6294/6294 15:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.200700</td>\n",
       "      <td>0.169679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.137951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.125691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6294, training_loss=0.16770618561149817, metrics={'train_runtime': 938.3223, 'train_samples_per_second': 107.323, 'train_steps_per_second': 6.708, 'total_flos': 1145799483401952.0, 'train_loss': 0.16770618561149817, 'epoch': 3.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_training_args = TrainingArguments(\n",
    "    output_dir=\"new_model\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "new_trainer = Trainer(\n",
    "    model=new_model,\n",
    "    args=new_training_args,\n",
    "    train_dataset=new_tokenized_ds[\"train\"].remove_columns([\"ner_tags\",'tokens']),\n",
    "    eval_dataset=new_tokenized_ds[\"validation\"].remove_columns([\"ner_tags\",'tokens']),\n",
    "    tokenizer=new_tokenizer,\n",
    "    data_collator=new_data_collator\n",
    ")\n",
    "\n",
    "new_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57b4cd43-f70c-480d-8ee5-0676fa6e6216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7194/7194 [01:04<00:00, 110.69it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"new_model/checkpoint-6294\"\n",
    "pipe = pipeline(\"ner\", model=model_name_or_path,tokenizer=new_tokenizer,device=0)\n",
    "preds = []\n",
    "for i in tqdm(data_test.values):\n",
    "  pred = pipe(' '.join(i[0]))\n",
    "  preds.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1c419a-c293-4921-a501-f6f3f9d4f2e5",
   "metadata": {},
   "source": [
    "Процент верных ответов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80e55ae1-f96e-48e4-9ed2-55b6d03d52a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'46.34%'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=0\n",
    "for v1,v2 in zip(data_test.values, preds):\n",
    "    true = list(filter(lambda x: x != 'O', v1[1]))\n",
    "    if true==[x.get(\"entity\") for x in v2]:\n",
    "        k+=1\n",
    "\"{:.2%}\".format(k/len(data_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a820133-0084-4b4e-bb81-220da4ec9003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
